<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Learning: MIT 6.S191 Introduction to Deep Learning - 2021 | Guillaume’s blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Learning: MIT 6.S191 Introduction to Deep Learning - 2021" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My notes/thoughts about the lecture" />
<meta property="og:description" content="My notes/thoughts about the lecture" />
<link rel="canonical" href="https://castorfou.github.io/blog/blog/learning-MIT-6.S191-2021.html" />
<meta property="og:url" content="https://castorfou.github.io/blog/blog/learning-MIT-6.S191-2021.html" />
<meta property="og:site_name" content="Guillaume’s blog" />
<meta property="og:image" content="https://castorfou.github.io/blog/images/DL.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-05T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://castorfou.github.io/blog/images/DL.jpg" />
<meta property="twitter:title" content="Learning: MIT 6.S191 Introduction to Deep Learning - 2021" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-02-05T00:00:00-06:00","datePublished":"2021-02-05T00:00:00-06:00","description":"My notes/thoughts about the lecture","headline":"Learning: MIT 6.S191 Introduction to Deep Learning - 2021","image":"https://castorfou.github.io/blog/images/DL.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://castorfou.github.io/blog/blog/learning-MIT-6.S191-2021.html"},"url":"https://castorfou.github.io/blog/blog/learning-MIT-6.S191-2021.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://castorfou.github.io/blog/feed.xml" title="Guillaume's blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Guillaume&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Learning: MIT 6.S191 Introduction to Deep Learning - 2021</h1><p class="page-description">My notes/thoughts about the lecture</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-02-05T00:00:00-06:00" itemprop="datePublished">
        Feb 5, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deep learning">deep learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#MIT">MIT</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#tensorflow">tensorflow</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#2521---intro-to-deep-learning---lecture-1">2/5/21 - Intro to Deep Learning - lecture 1</a></li>
<li class="toc-entry toc-h2"><a href="#21521---deep-sequence-modeling---lecture-2">2/15/21 - Deep Sequence Modeling - lecture 2</a></li>
<li class="toc-entry toc-h2"><a href="#21621---intro-to-tensorflow--music-generation---software-lab-1">2/16/21 - Intro to TensorFlow;  Music Generation - software lab 1</a></li>
<li class="toc-entry toc-h2"><a href="#22221---deep-computer-vision---lecture-3">2/22/21 - Deep Computer Vision - lecture 3</a></li>
<li class="toc-entry toc-h2"><a href="#3121---deep-generative-modeling---lecture-4">3/1/21 - Deep Generative Modeling - lecture 4</a></li>
<li class="toc-entry toc-h2"><a href="#3121---de-biasing-facial-recognition-systems---software-lab-2">3/1/21 - De-biasing Facial Recognition Systems - Software Lab 2</a></li>
<li class="toc-entry toc-h2"><a href="#3821---deep-reinforcement-learning---lecture-5">3/8/21 - Deep Reinforcement Learning - lecture 5</a></li>
<li class="toc-entry toc-h2"><a href="#31521---limitations-and-new-frontiers---lecture-6">3/15/21 - Limitations and New Frontiers - lecture 6</a></li>
<li class="toc-entry toc-h2"><a href="#31521---pixels-to-control-learning---software-lab-3">3/15/21 - Pixels-to-Control Learning - Software Lab 3</a></li>
<li class="toc-entry toc-h2"><a href="#32221---evidential-deep-learning-and-uncertainty---lecture-7">3/22/21 - Evidential Deep Learning and Uncertainty - lecture 7</a></li>
<li class="toc-entry toc-h2"><a href="#32921---bias-and-fairness---lecture-8">3/29/21 - Bias and Fairness - lecture 8</a></li>
<li class="toc-entry toc-h2"><a href="#41521---learning-for-information-extraction---lecture-9">4/15/21 - Learning for Information Extraction - lecture 9.</a></li>
<li class="toc-entry toc-h2"><a href="#42721---taming-dataset-bias---lecture-10">4/27/21 - Taming Dataset Bias - lecture 10</a></li>
<li class="toc-entry toc-h2"><a href="#43021----towards-ai-for-3d-content-creation---lecture-11">4/30/21 -  Towards AI for 3D Content Creation - lecture 11</a>
<ul>
<li class="toc-entry toc-h5"><a href="#sanja-fidler-professor-u-of-toronto-and-head-of-ai-at-nvidia">Sanja Fidler; Professor U. of Toronto and Head of AI at NVIDIA</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#43021----ai-in-healthcare---lecture-12">4/30/21 -  AI in Healthcare - lecture 12</a>
<ul>
<li class="toc-entry toc-h5"><a href="#katherine-chou-director-of-research-and-innovations-google">Katherine Chou; Director of Research and Innovations, Google</a></li>
</ul>
</li>
</ul><p>From <a href="http://introtodeeplearning.com/">http://introtodeeplearning.com/</a></p>

<p>I keep all content (lectures, notebooks) in <a href="https://github.com/castorfou/mit_6s191">github</a></p>

<p>This is done with google contribution, and therefore all examples are in tensorflow. I will try to adapt notebooks in PyTorch.</p>

<h2 id="2521---intro-to-deep-learning---lecture-1">
<a class="anchor" href="#2521---intro-to-deep-learning---lecture-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>2/5/21 - Intro to Deep Learning - lecture 1</h2>

<p>Lecturer: Alexander Amini</p>

<p>Intro is just jaw-dropping!</p>

<p><a href="https://youtu.be/5tvmMX8r_OM?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;t=40">2020 intro</a> was top.</p>

<p><a href="https://youtu.be/5tvmMX8r_OM?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;t=149">2021 intro</a> is just awesome.</p>

<p>It is a standard overview of simple deep learning concepts: Perceptron, multi-perceptron, dense layers, loss, gradient-descent, backprop, SGD, regularization, dropout, early stoppping</p>

<h2 id="21521---deep-sequence-modeling---lecture-2">
<a class="anchor" href="#21521---deep-sequence-modeling---lecture-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>2/15/21 - Deep Sequence Modeling - lecture 2</h2>

<p>New lecturer: Ava Soleimany</p>

<p>Nice introduction to sequence modeling with Many-to-One, One-to-Many, Many-to-Many.</p>

<p>RNN and implementation in TensorFlow. And NLP examples: next word problem. (and NLP concepts such as Vocabulary, Indexing, Embedding)</p>

<p>And what we need for sequence modeling:</p>

<ul>
  <li>handle variable-length sequences</li>
  <li>track long-term dependencies</li>
  <li>maintain information about order</li>
  <li>share parameters across the sequence</li>
</ul>

<p>Backpropagation through time and problem of exploding/vanishing gradients.</p>

<p>Against exploding: gradient clipping. Against vanishing: 3 ways explained - activation functions, weight init, network arch.</p>

<p>Gated cell: to control what information is passed through. Ex: LSTM Long Short Term Memory. They support something closed to Forget Store Update Output. Ava explains graphically which part of LSTM cells is providing which function.</p>

<p>And then examples: Music generation (to generate 4th movement of last symphony from Schubert!), sentiment classification, machine translation (with Attention mechanisms which provide learnable memory access to solve Not long memory), trajectory prediction, environmental modeling.</p>

<h2 id="21621---intro-to-tensorflow--music-generation---software-lab-1">
<a class="anchor" href="#21621---intro-to-tensorflow--music-generation---software-lab-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>2/16/21 - Intro to TensorFlow;  Music Generation - software lab 1</h2>

<p>As an exercise I have completed labs in TensorFlow and adapted them in <a href="https://github.com/castorfou/mit_6s191/blob/main/introtodeeplearning/lab1/Part1_TensorFlow_transposed%20to%20PyTorch.ipynb">PyTorch</a>.</p>

<p>With LSTM, I ran into this error: <code class="language-plaintext highlighter-rouge">UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]</code></p>

<p>Which is solved by calling <a href="https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth"><code class="language-plaintext highlighter-rouge">tf.config.experimental.set_memory_growth</code></a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span> 
<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="c1"># Currently, memory growth needs to be the same across GPUs
</span>    <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
      <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
  <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c1"># Memory growth must be set before GPUs have been initialized
</span>    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div></div>

<p>Music lab is nice to play with. I am not sure I would be able to convert to PyTorch. It would require time!</p>

<h2 id="22221---deep-computer-vision---lecture-3">
<a class="anchor" href="#22221---deep-computer-vision---lecture-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>2/22/21 - Deep Computer Vision - lecture 3</h2>

<p>I have never been a big fan of computer vision.</p>

<p>I like the idea developed by Alexander Amini about <strong>hierarchy of features</strong>. (low level: edges, spots; mid level: eyes, noses)</p>

<p>And how he explains limitation of FC layers for visual detection, and introduction of spatial structure (feature extraction with convolutions)</p>

<p>Some nice examples of hand-engineered convolution filters for different needs: sharpen, edge detect, strong edge detect.</p>

<p>Then classic explanations of CNN with convolution, max pooling.</p>

<p>I like the way classification problems are broken down between feature learning (convolution+relu, pooling, repeated several times) and classification (flatten, FC, softmax) which is a task learning part.</p>

<p>The second part (task learning part) can be anything: classification, object detection, segmentation, probabilistic control, …</p>

<p><img src="../images/mit_6S191_lec3_cnn_architectures.png" alt=""></p>

<p>Nice explanation of R-CNN to learn region proposals.</p>

<p>Introduction to Software lab2: de-biaising facial recognition systems.</p>

<h2 id="3121---deep-generative-modeling---lecture-4">
<a class="anchor" href="#3121---deep-generative-modeling---lecture-4" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/1/21 - Deep Generative Modeling - lecture 4</h2>

<p>From pattern discovered from data (underlying structure of the data), generate examples following these patterns.</p>

<p><strong>Autoencoder</strong>: foundational generative model which builds up latent variable representation by self-encoding the input. To train such network, we create a decoder to go from latent variable to generated output, and then compare input to generated output.</p>

<p><img src="../images/mit_6S191_lec4_autoencoders.png" alt=""></p>

<p><strong>Variational autoencoder (vae)</strong>: with vae we try to encode inputs as distributions defined by mean <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span> and variance <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>. And we want to achieve continuity and completeness:</p>

<ul>
  <li>continuity: points that are close in latent space –&gt; similar content after decoding</li>
  <li>completeness: sampling from latent space –&gt; ‘meaningful’ content after decoding</li>
</ul>

<p>Regularization is pushing to get these properties.</p>

<p><img src="../images/mit_6S191_lec4_vae_regularization.png" alt=""></p>

<p>And the learning process is about minimizing reconstruction loss + a regularization term:</p>

<p><img src="../images/mit_6S191_lec4_vae_loss.png" alt=""></p>

<p>Ava is then explaining the smart trick to allow backpropagation to happen. Indeed by introducing stochastic term in the sampling layer, we are breaking the backpropagation logic.</p>

<p>We are moving z from a normal distribution to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">μ</span></span></span></span>+<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>.<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> follow a normal distribution of mean 0, std 1.</p>

<p>Explanation then of space disentanglement via <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>-VAEs. It allows latent variables to be independent.</p>

<p><img src="../images/mit_6S191_lec4_vae_beta.png" alt=""></p>

<p>And then some introduction about <em>*GANs</em> (Generative Adversarial Network) which are a way to make a generative model by having 2 neural networks (generator and discriminator) compete with each other.</p>

<p>And share some recent advances on GAN such as StyleGAN(2), conditional GAN, CycleGAN. CycleGAN is famous for turning horses in zebras, but it can be used to transform speech as well (used in the synthesis of Obama’s voice)</p>

<p><img src="../images/mit_6S191_lec4_generative_summary.png" alt=""></p>

<h2 id="3121---de-biasing-facial-recognition-systems---software-lab-2">
<a class="anchor" href="#3121---de-biasing-facial-recognition-systems---software-lab-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/1/21 - De-biasing Facial Recognition Systems - Software Lab 2</h2>

<p><a href="https://github.com/castorfou/mit_6s191/blob/main/introtodeeplearning/lab2/Part1_MNIST.ipynb">Part 1 MNIST</a></p>

<p>starts with FC layers. With some overfitting but a good accuracy of 96%.</p>

<p>then move to a CNN architecture. I ran into <a href="https://github.com/tensorflow/tensorflow/issues/24828">gpu issues</a>.  Accuracy is now 99%.</p>

<p>I didn’t manage to make the last part working. (using tape.gradient)</p>

<p><a href="https://github.com/castorfou/mit_6s191/blob/main/introtodeeplearning/lab2/Part2_Debiasing.ipynb">Part 2 Debiasing</a></p>

<p>Fit a CNN model to classify faces based on celebA dataset. And see the bias effect by predicting on Fitzpatrick scale skin type classification system.</p>

<p>Use VAE to learn latent structure.</p>

<p><img src="https://i.ibb.co/3s4S6Gc/vae.jpg" alt="The concept of a VAE"></p>

<p>To then debias using DB-VAE model.</p>

<p><img src="https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab2/img/DB-VAE.png" alt="DB-VAE"></p>

<p>There is a lack of progressive unit tests to validate each step. Cannot go to the end.</p>

<p>Would be interested to see how to apply to non computer vision problems.</p>

<h2 id="3821---deep-reinforcement-learning---lecture-5">
<a class="anchor" href="#3821---deep-reinforcement-learning---lecture-5" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/8/21 - Deep Reinforcement Learning - lecture 5</h2>

<p>Q-function captures the expected total future reward an agent in state <em>s</em> can receive by executing a certain action <em>a</em>.</p>

<p>Distinction between <strong>Value Learning</strong> (learn Q function) and <strong>Policy Learning</strong> (find directly <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span>(s)).</p>

<p><img src="../images/mit_6S191_lec5_pg_dqn.png" alt=""></p>

<p><strong>Value Learning or DQN</strong></p>

<p><img src="../images/mit_6S191_lec5_dqn_summary.png" alt=""></p>

<p><img src="../images/mit_6S191_lec5_dqn_downsides.png" alt=""></p>

<p>The key thing is about handling of continuous actions.</p>

<p>Let’s see how to do it with policy learning:</p>

<p><strong>Policy learning or Policy Gradient (PG)</strong></p>

<p><img src="../images/mit_6S191_lec5_pg_key_idea.png" alt=""></p>

<p><img src="../images/mit_6S191_lec5_pg_training.png" alt=""></p>

<p>Alexanders ends the lecture by discussing about Deepmind progress:</p>

<ul>
  <li>alphaGo - 2016: with a pretrain in supervised mode then standard DRL</li>
  <li>alphaGo Zero - 2017: standard DRL without pretraining</li>
  <li>alphaZero - 2018: standard DRL without pretraining and applied to several games (Go, Chess, Shogi)</li>
  <li>MuZero - 2020: learns the rules of the game by itself, create unknown dynamics</li>
</ul>

<h2 id="31521---limitations-and-new-frontiers---lecture-6">
<a class="anchor" href="#31521---limitations-and-new-frontiers---lecture-6" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/15/21 - Limitations and New Frontiers - lecture 6</h2>

<p><strong>Universal Approximation Theorem</strong>: A feedforward network with a single layer is sufficient to approximate, to an arbitrary precision, any continuous function.</p>

<p>Ava emphasizes importance of training data (e.g. for generalization) and mentions a paper called “<a href="https://arxiv.org/abs/1611.03530">Understanding Deep Neural Networks Requires Rethinking Generalization</a>”.</p>

<p>Some fail examples with dogs colorization (BW -&gt; colors) creating pink zone under the mouth.</p>

<p>And another one with Tesla autopilot. It motivates working on <strong>uncertainty in Deep Learning</strong>.</p>

<ul>
  <li>we need uncertainty metrics to assess the noise inherent to the data: <em>aleatoric uncertainty</em>
</li>
  <li>we need uncertainty metrics to assess the network’s confidence in its predictions: <em>epistemic uncertainty</em>
</li>
</ul>

<p>Ava cites an example of a real 3D printed turtle designed to fool a classifier from turtle to rifle.</p>

<p><strong>New frontier: Encoding Structure into Deep Learning.</strong></p>

<p>CNN is a nice way to extract features from an image. But not all kind of data can express features in an euclidean way. Graphs is used as a structure for representing data in a lot of cases.</p>

<p>It drives us to <strong>Graph Convolutional Networks</strong> (GCNs). The graph convolutional operator is going to associate weights with each of the edges and apply the weights across the graph and then the kernel is going to be moved to the next node in the graph extracting information about its local connectivity. That local information is going to be aggregated and the NN is going to then learn a function that encodes that local information into a higher level representation.</p>

<p><strong>New frontier: Automated Machine Learning &amp; AI.</strong></p>

<p>Using a neural architecture search algorithm. At each step the model samples a brand new network. For each layer, defines number of fileters, filet height, width, stride height, width, nbr of fileters, etc. Update RNN controller based on the accuracy of the child network after training.</p>

<p>From autoML to autoAI: an automated complete pipeline for designing and deploying ML and AI models.</p>

<h2 id="31521---pixels-to-control-learning---software-lab-3">
<a class="anchor" href="#31521---pixels-to-control-learning---software-lab-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/15/21 - Pixels-to-Control Learning - Software Lab 3</h2>

<p>This is about reinforcement learning.</p>

<p><img src="https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg" alt="alt text"></p>

<p>We install (apt) xvfb and python-opengl.</p>

<p>And will learn with cartpole and pong.</p>

<p>Still this issue</p>

<blockquote>
  <p>UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential_8/conv2d_4/Conv2D (defined at <ipython-input-21-f109a85f869a>:19) ]] [Op:__inference_distributed_function_2442603]</ipython-input-21-f109a85f869a></p>
</blockquote>

<p>Solved by running</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Currently, memory growth needs to be the same across GPUs
</span>        <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">logical_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">list_logical_devices</span><span class="p">(</span><span class="s">'GPU'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gpus</span><span class="p">),</span> <span class="s">"Physical GPUs,"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">logical_gpus</span><span class="p">),</span> <span class="s">"Logical GPUs"</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># Memory growth must be set before GPUs have been initialized
</span>        <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div></div>

<p>I couldn’t go through the training of Pong agent due to GPU limitation?</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2021-03-15 10:54:19.479775: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at conv_grad_input_ops.cc:1254 : Resource exhausted: OOM when allocating tensor with shape[3944,48,10,10] and <span class="nb">type </span>float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfcbash
</code></pre></div></div>

<h2 id="32221---evidential-deep-learning-and-uncertainty---lecture-7">
<a class="anchor" href="#32221---evidential-deep-learning-and-uncertainty---lecture-7" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/22/21 - Evidential Deep Learning and Uncertainty - lecture 7</h2>

<p><img src="../images/mit_6S191_lec7_continuous.png" alt=""></p>

<p><img src="../images/mit_6S191_lec7_likelihood.png" alt=""></p>

<p><img src="../images/mit_6S191_lec7_wrapup.png" alt=""></p>

<h2 id="32921---bias-and-fairness---lecture-8">
<a class="anchor" href="#32921---bias-and-fairness---lecture-8" aria-hidden="true"><span class="octicon octicon-link"></span></a>3/29/21 - Bias and Fairness - lecture 8</h2>

<p>This starts as a standard lecture about bias.</p>

<p>I like emphasis about bias that could stand in all stages of AI life cycle:</p>

<ul>
  <li>data (obviously)</li>
  <li>model</li>
  <li>training and deployment</li>
  <li>evaluation</li>
  <li>interpretation</li>
</ul>

<p>Good explanation about biases due to <strong>class imbalance</strong>. It develops my intuition about it.</p>

<p><strong>Balanced batches</strong> can be the answer.</p>

<p><strong>Example weighting</strong> is another option using inverse frequency as a weight.</p>

<p><img src="../images/mit_6S191_lec8_fairness.png" alt=""></p>

<p>Adversarial learning to mitiage Bias.</p>

<p>Application in NLP to complete analogies. He is to she, as doctor is to ?</p>

<p>Same thing with Learned Latent Structure. (can be used to create fair and representative dataset)</p>

<p><img src="../images/mit_6S191_lec8_summary.png" alt=""></p>

<h2 id="41521---learning-for-information-extraction---lecture-9">
<a class="anchor" href="#41521---learning-for-information-extraction---lecture-9" aria-hidden="true"><span class="octicon octicon-link"></span></a>4/15/21 - Learning for Information Extraction - lecture 9.</h2>

<p><a href="https://www.youtube.com/watch?v=WkUYsVC3hKI&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=9">Deep CPCFG for Information Extraction </a></p>

<p>Lecturer: Nigel Duffy and Freddy Chua, Ernst &amp; Young AI Labs</p>

<p>Focus is about document intelligence (extract info from business documents)</p>

<p>e.g. extract information from semi-structured documents such as tax forms (souvenirs ;))</p>

<p><img src="../images/mit_6S191_lec9_endtoend_training.png" alt=""></p>

<h2 id="42721---taming-dataset-bias---lecture-10">
<a class="anchor" href="#42721---taming-dataset-bias---lecture-10" aria-hidden="true"><span class="octicon octicon-link"></span></a>4/27/21 - Taming Dataset Bias - lecture 10</h2>

<p><a href="https://www.youtube.com/watch?v=eS-OHAHOqU0&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=11">video</a></p>

<p>dataset bias and training shift</p>

<p>(from one city to another (summer vs winter), from simulated to real control, from one culture to another)</p>

<p>Can fix with more data …(can be very expensive if we want to address all combinations) or use unlabeled data ?</p>

<p><img src="../images/mit_6S191_lec10_domain_adaptation.png" alt=""></p>

<p>Adversarial approach to fool a domain discriminator. (domain discriminator trained to distinguished source and target domains)</p>

<p>Another approach is pixel alignment.</p>

<h2 id="43021----towards-ai-for-3d-content-creation---lecture-11">
<a class="anchor" href="#43021----towards-ai-for-3d-content-creation---lecture-11" aria-hidden="true"><span class="octicon octicon-link"></span></a>4/30/21 -  Towards AI for 3D Content Creation - lecture 11</h2>

<p><a href="https://www.youtube.com/watch?v=lkkFcg9k9ho&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=12">video</a></p>

<h5 id="sanja-fidler-professor-u-of-toronto-and-head-of-ai-at-nvidia">
<a class="anchor" href="#sanja-fidler-professor-u-of-toronto-and-head-of-ai-at-nvidia" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sanja Fidler; Professor U. of Toronto and Head of AI at NVIDIA</h5>

<h2 id="43021----ai-in-healthcare---lecture-12">
<a class="anchor" href="#43021----ai-in-healthcare---lecture-12" aria-hidden="true"><span class="octicon octicon-link"></span></a>4/30/21 -  AI in Healthcare - lecture 12</h2>

<p><a href="https://www.youtube.com/watch?v=cvXVK8oqU4Q&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=13">video</a></p>

<h5 id="katherine-chou-director-of-research-and-innovations-google">
<a class="anchor" href="#katherine-chou-director-of-research-and-innovations-google" aria-hidden="true"><span class="octicon octicon-link"></span></a>Katherine Chou; Director of Research and Innovations, Google</h5>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="castorfou/guillaume_blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/blog/learning-MIT-6.S191-2021.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Journey for a datascientist</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/castorfou" target="_blank" title="castorfou"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/GuillaumeRamel1" target="_blank" title="GuillaumeRamel1"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
